<!DOCTYPE html><!--  This site was created in Webflow. https://webflow.com  --><!--  Last Published: Wed Oct 30 2024 06:52:08 GMT+0000 (Coordinated Universal Time)  -->
<html data-wf-page="670eca02bcb89791cb965a79" data-wf-site="670eca02bcb89791cb965a72">
<head>
  <meta charset="utf-8">
  <title>project4</title>
  <meta content="width=device-width, initial-scale=1" name="viewport">
  <meta content="Webflow" name="generator">
  <link href="css/normalize.css" rel="stylesheet" type="text/css">
  <link href="css/webflow.css" rel="stylesheet" type="text/css">
  <link href="css/project4-97ee53.webflow.css" rel="stylesheet" type="text/css">
  <script type="text/javascript">!function(o,c){var n=c.documentElement,t=" w-mod-";n.className+=t+"js",("ontouchstart"in o||o.DocumentTouch&&c instanceof DocumentTouch)&&(n.className+=t+"touch")}(window,document);</script>
  <link href="images/favicon.ico" rel="shortcut icon" type="image/x-icon">
  <link href="images/webclip.png" rel="apple-touch-icon">
</head>
<body>
  <div class="w-layout-blockcontainer w-container">
    <h1>Project 4</h1>
  </div>
  <div class="w-layout-blockcontainer w-container">
    <h2>Take Photos </h2>
  </div>
  <div class="w-layout-blockcontainer w-container">
    <div class="w-layout-blockcontainer w-container">
      <p>I took some photos from my daily life, which contains my room and some Berkeley views. Meanwhile, I gained some photos which were taken by my classmates. After taking the photo, I utilized the tool given by project 3 to establish the points pairs which help me to calculate homography matrixs. </p>
    </div>
  </div>
  <div class="w-layout-blockcontainer w-container">
    <h2>Calculate Homography</h2>
    <div class="w-layout-blockcontainer w-container">
      <p> I write a <code>compute_homography</code> function calculates a Homography Matrix between two images, a transformation that allows for perspective shifts, widely used in tasks like image alignment, stereoscopy, and augmented reality within the field of computer vision. The function first ensures that both sets of input points are equal in number and contain at least four points, as these are the prerequisites for computing a homography. It then normalizes these points to boost numerical stability and reduce errors due to scale differences. An equation system, derived from the normalized points, articulates the linear relations that the points must satisfy before and after the transformation. Singular Value Decomposition (SVD) is used to solve this system, effectively handling noise and numerical issues in the data, ensuring an optimal solution even under imperfect conditions. Finally, the computed homography matrix is transformed back to the original coordinate system through a denormalization process.</p>
    </div>
  </div>
  <div class="w-layout-blockcontainer w-container">
    <h2>Image Warp</h2>
  </div>
  <div class="w-layout-blockcontainer w-container">
    <p>The <code>warpImage</code> function performs a perspective transformation of images using a homography matrix, commonly used in computer vision for tasks like image stitching and perspective correction. Initially, the function determines the dimensions of the image and computes the coordinates of its four corners, converting these into homogeneous coordinates. Using the homography matrix, it transforms these coordinates to new positions and converts the transformed coordinates back to a two-dimensional format. Based on these transformed coordinates, the function defines the boundaries of the transformed image and creates a new coordinate grid that covers the entire transformed area. By inverting the homography matrix, it locates the corresponding positions in the original image for each point on the grid and calculates the pixel values at these positions using interpolation methods, ultimately generating the transformed image. This process ensures the continuity and integrity of the image content while maintaining the quality and visual effects of the transformation through precise interpolation.4</p>
    <section>
      <h2><strong>Image Rectification</strong></h2>
      <section>
        <div class="w-layout-vflex"><img src="images/desk_shift.jpg" loading="lazy" width="1094" sizes="(max-width: 767px) 100vw, (max-width: 991px) 95vw, 940px" alt="" srcset="images/desk_shift-p-500.jpg 500w, images/desk_shift-p-800.jpg 800w, images/desk_shift-p-1080.jpg 1080w, images/desk_shift-p-1600.jpg 1600w, images/desk_shift.jpg 1875w"><img src="images/word_shift.jpg" loading="lazy" sizes="(max-width: 767px) 100vw, (max-width: 991px) 95vw, 940px" srcset="images/word_shift-p-500.jpg 500w, images/word_shift-p-800.jpg 800w, images/word_shift-p-1080.jpg 1080w, images/word_shift-p-1600.jpg 1600w, images/word_shift.jpg 1687w" alt="" class="image-3"></div>
      </section>
    </section>
    <div class="w-layout-blockcontainer w-container">
      <h2>Image Blending</h2>
      <div class="w-layout-blockcontainer w-container">
        <p>The <code>blend_image</code> function is designed to achieve a smooth blend between two images in a specified overlapping area. This function is typically used in scenarios such as image stitching, where two images partially overlap and a seamless transition is desired. <br><br>The function begins by defining an internal function <code>pad_image_to_target</code> which is used to resize images to a specified target size by adding padding to adjust the image position. This ensures that both images align properly for the blending process. <br><br>The main <code>blend_image</code> function takes two images <code>image1</code> and <code>image2</code>, an <code>overlap_ratio</code> that specifies the proportion of the overlap, an <code>offset</code> to adjust the position, and a <code>direction</code> parameter (default &quot;w&quot; for west, indicating a horizontal left-to-right direction). It first calculates the target dimensions to which both images need to be extended so they can be processed on the same canvas.<br><br>Next, the function uses <code>pad_image_to_target</code> to pad and position both images appropriately. Depending on the specified <code>direction</code>, the function computes the width of the blend area and the dimensions of the new canvas.<br><br>A blending mask <code>mask</code> is then created, which transitions from 0 (black, representing full use of <code>image1</code>) to 1 (white, representing full use of <code>image2</code>) across the blending area. The actual blending is carried out using the Laplacian pyramid technique, which handles image details better, creating a visually natural blending effect.<br><br>Finally, the <code>image_blend</code> function performs multi-level blending using Laplacian and Gaussian pyramids to ensure that every detail level transitions smoothly from coarse to fine. Through this method, the function ultimately returns a blended image that visually creates a smooth transition in the overlapping section of the two original images.4</p>
        <div class="w-layout-vflex flex-block"><img src="images/building0.jpg" loading="lazy" width="217" sizes="217px" alt="" srcset="images/building0-p-500.jpg 500w, images/building0.jpg 614w" class="image-5"><img src="images/building1.jpg" loading="lazy" width="217" sizes="217px" alt="" srcset="images/building1-p-500.jpg 500w, images/building1.jpg 614w" class="image-6"></div>
      </div>
    </div>
  </div>
  <div class="w-layout-hflex flex-block-2"><img src="images/building_warp.jpg" loading="lazy" width="234" sizes="234px" alt="" srcset="images/building_warp-p-500.jpg 500w, images/building_warp-p-800.jpg 800w, images/building_warp.jpg 885w" class="image-4"><img src="images/building_blend.jpg" loading="lazy" width="350" sizes="(max-width: 479px) 100vw, 350px" alt="" srcset="images/building_blend-p-500.jpg 500w, images/building_blend-p-800.jpg 800w, images/building_blend-p-1080.jpg 1080w, images/building_blend.jpg 1328w" class="image-7"></div>
  <div class="w-layout-hflex"><img src="images/house0.jpg" loading="lazy" width="217" alt="" class="image-8"><img src="images/house1.jpg" loading="lazy" width="217" height="Auto" alt="" class="image-9"></div>
  <div class="w-layout-vflex"><img src="images/house0_warp.jpg" loading="lazy" width="217" alt="" class="image-10"><img src="images/house0_house1_blend.jpg" loading="lazy" width="384" sizes="(max-width: 479px) 100vw, 384px" alt="" srcset="images/house0_house1_blend-p-500.jpg 500w, images/house0_house1_blend.jpg 540w" class="image-11"></div>
  <div class="w-layout-hflex"><img src="images/wth1.jpg" loading="lazy" width="365" sizes="(max-width: 479px) 100vw, 365px" alt="" srcset="images/wth1-p-500.jpg 500w, images/wth1-p-800.jpg 800w, images/wth1.jpg 1451w" class="image-12"><img src="images/wth2.jpg" loading="lazy" width="367" sizes="(max-width: 479px) 100vw, 367px" alt="" srcset="images/wth2-p-500.jpg 500w, images/wth2-p-800.jpg 800w, images/wth2.jpg 1306w" class="image-13"></div>
  <div class="w-layout-vflex"><img src="images/view_warp.jpg" loading="lazy" width="351" sizes="(max-width: 479px) 100vw, 351px" alt="" srcset="images/view_warp-p-500.jpg 500w, images/view_warp-p-800.jpg 800w, images/view_warp-p-1080.jpg 1080w, images/view_warp-p-1600.jpg 1600w, images/view_warp-p-2000.jpg 2000w, images/view_warp.jpg 2153w" class="image-14"><img src="images/view_blend.jpg" loading="lazy" width="501" sizes="(max-width: 767px) 100vw, 501px" alt="" srcset="images/view_blend-p-500.jpg 500w, images/view_blend-p-800.jpg 800w, images/view_blend-p-1080.jpg 1080w, images/view_blend-p-1600.jpg 1600w, images/view_blend-p-2000.jpg 2000w, images/view_blend-p-2600.jpg 2600w, images/view_blend.jpg 3144w" class="image-15"></div>
  <div class="w-layout-blockcontainer w-container">
    <h2>Detecting corner features</h2>
    <p>I utilized the function that provided on the website to detect the corner features. Here is the visualization of this part.</p>
    <div class="w-layout-hflex"><img src="images/coord_result0.jpg" loading="lazy" width="300" sizes="(max-width: 479px) 100vw, 300px" alt="" srcset="images/coord_result0.jpg 500w, images/coord_result0.jpg 800w"><img src="images/coord_result1.jpg" loading="lazy" width="300" sizes="(max-width: 479px) 100vw, 300px" alt="" srcset="images/coord_result1.jpg 500w, images/coord_result1.jpg 800w"><img src="images/coord_result1_1.jpg" loading="lazy" width="300" sizes="(max-width: 479px) 100vw, 300px" alt="" srcset="images/coord_result1_1-p-500.jpg 500w, images/coord_result1_1.jpg 800w"></div>
    <div class="w-layout-hflex"><img src="images/coord_result0_1.jpg" loading="lazy" width="300" sizes="(max-width: 479px) 100vw, 300px" alt="" srcset="images/coord_result0_1-p-500.jpg 500w, images/coord_result0_1.jpg 800w"><img src="images/coord_result0_2.jpg" loading="lazy" width="300" sizes="(max-width: 479px) 100vw, 300px" alt="" srcset="images/coord_result0_2-p-500.jpg 500w, images/coord_result0_2.jpg 800w"><img src="images/coord_result1_2.jpg" loading="lazy" width="300" sizes="(max-width: 479px) 100vw, 300px" alt="" srcset="images/coord_result1_2-p-500.jpg 500w, images/coord_result1_2.jpg 800w"></div>
    <div class="w-layout-blockcontainer w-container">
      <p>Firstly, I input an image, a set of coordinates, and two window size parameters: a larger window (<code>large_window</code>) and a smaller central window (<code>small_window</code>). To facilitate the processing of coordinates at the image edges, the original image is initially padded around the edges with a width equal to half of the large window, using a padding value of 0. For each coordinate, the function extracts a large window region centered around the point from the padded image, then further extracts a smaller window area from the center of this region. This smaller area&#x27;s pixel values are normalized (by subtracting the mean and dividing by the standard deviation) only if the standard deviation of this area is greater than zero, and the processed data is flattened into a one-dimensional array to serve as a descriptor. All these descriptors are eventually stored and returned as a NumPy array.</p>
      <h2>Feature Descriptors</h2>
    </div>
  </div>
  <div class="w-layout-blockcontainer w-container">
    <h2>Match Descriptors</h2>
    <h3>Adaptive Non-maximal Suppression</h3>
    <p>First, I input a set of coordinates <code>coords</code>, an image&#x27;s keypoint response matrix <code>h</code>, and an optional parameter for the number of points <code>num_points</code>. The function initializes an infinite distance array <code>radii</code>, and for each point, it calculates and updates the minimum distance to other points with higher response values. Then, it sorts these distances in descending order and selects the top <code>num_points</code> with the largest distances, returning their coordinates. This method reduces the number of keypoints, thereby lightening the computational load for subsequent processing while retaining the points most likely to represent significant features. It is particularly well-suited for tasks involving image matching and recognition. (This block I refered to several websites and paper such as CSDN and Github). Here is the result. </p>
    <div class="w-layout-hflex"><img src="images/maximal_suppression_coord_result0.jpg" loading="lazy" width="400" sizes="(max-width: 479px) 100vw, 400px" alt="" srcset="images/maximal_suppression_coord_result0.jpg 500w, images/maximal_suppression_coord_result0.jpg 800w"><img src="images/maximal_suppression_coord_result1.jpg" loading="lazy" width="400" sizes="(max-width: 479px) 100vw, 400px" alt="" srcset="images/maximal_suppression_coord_result1.jpg 500w, images/maximal_suppression_coord_result1.jpg 800w"></div>
    <div class="w-layout-hflex"><img src="images/maximal_suppression_coord_result0_2.jpg" loading="lazy" width="400" sizes="(max-width: 479px) 100vw, 400px" alt="" srcset="images/maximal_suppression_coord_result0_2-p-500.jpg 500w, images/maximal_suppression_coord_result0_2.jpg 800w"><img src="images/maximal_suppression_coord_result1_2.jpg" loading="lazy" width="400" sizes="(max-width: 479px) 100vw, 400px" alt="" srcset="images/maximal_suppression_coord_result1_2-p-500.jpg 500w, images/maximal_suppression_coord_result1_2.jpg 800w"></div>
    <div class="w-layout-hflex"><img src="images/maximal_suppression_coord_result0_1.jpg" loading="lazy" width="400" sizes="(max-width: 479px) 100vw, 400px" alt="" srcset="images/maximal_suppression_coord_result0_1-p-500.jpg 500w, images/maximal_suppression_coord_result0_1.jpg 800w"><img src="images/maximal_suppression_coord_result1_1.jpg" loading="lazy" width="400" sizes="(max-width: 479px) 100vw, 400px" alt="" srcset="images/maximal_suppression_coord_result1_1-p-500.jpg 500w, images/maximal_suppression_coord_result1_1.jpg 800w"></div>
    <p>I use squared Euclidean distance to calculate the similarity between descriptors, and apply Lowe&#x27;s ratio test to enhance the reliability of the matches. The function first iterates through each descriptor in the first set, <code>descriptors1</code>, computing the squared Euclidean distance to all descriptors in the second set, <code>descriptors2</code>. It then identifies the two closest points for each descriptor. If the closest distance is less than a set ratio (defaulted to 0.75 times) of the second closest distance, the pair of descriptors is considered a valid match and their indices are added to the match list. <br>Here are some paired descriptors in different images.</p>
    <div class="w-layout-hflex"><img src="images/building_descriptors.jpg" loading="lazy" sizes="(max-width: 767px) 100vw, (max-width: 991px) 95vw, 940px" srcset="images/building_descriptors.jpg 500w, images/building_descriptors.jpg 800w, images/building_descriptors.jpg 1080w, images/building_descriptors.jpg 1358w" alt=""></div>
    <div class="w-layout-hflex"><img src="images/house_descriptors.jpg" loading="lazy" sizes="(max-width: 767px) 100vw, (max-width: 991px) 95vw, 940px" srcset="images/house_descriptors.jpg 500w, images/house_descriptors.jpg 800w, images/house_descriptors.jpg 1080w, images/house_descriptors.jpg 1363w" alt=""></div>
    <div class="w-layout-hflex"><img src="images/wth_descriptors.jpg" loading="lazy" sizes="(max-width: 767px) 100vw, (max-width: 991px) 95vw, 940px" srcset="images/wth_descriptors.jpg 500w, images/wth_descriptors.jpg 800w, images/wth_descriptors.jpg 1080w, images/wth_descriptors.jpg 1322w" alt=""></div>
  </div>
  <div class="w-layout-blockcontainer w-container">
    <h2>RANSAC</h2>
    <p>I start by initializing the maximum number of inliers, the best homography matrix, and the list of inliers. Within the set number of iterations, each iteration randomly selects four pairs of source and destination points, computes the homography matrix, and transforms all source points according to this matrix. Afterwards, I calculate the distance between the transformed points and the destination points, and determine which points have errors within the threshold, marking them as inliers. If the number of inliers from the current iteration exceeds the previous record, then the best homography matrix and its list of inliers are updated. Finally, the function returns the homography matrix and list of inliers that had the most inliers found during the iterative process. Here are the result which shows the inliner points.</p>
    <div class="w-layout-hflex"><img src="images/inliner0.jpg" loading="lazy" width="400" height="Auto" alt="" srcset="images/inliner0.jpg 500w, images/inliner0.jpg 800w" sizes="(max-width: 479px) 100vw, 400px"><img src="images/inliner1.jpg" loading="lazy" width="400" sizes="(max-width: 479px) 100vw, 400px" alt="" srcset="images/inliner1.jpg 500w, images/inliner1.jpg 800w"></div>
    <div class="w-layout-hflex"><img src="images/inliner0_1.jpg" loading="lazy" width="400" sizes="(max-width: 479px) 100vw, 400px" alt="" srcset="images/inliner0_1-p-500.jpg 500w, images/inliner0_1.jpg 800w"><img src="images/inliner1_1.jpg" loading="lazy" width="400" sizes="(max-width: 479px) 100vw, 400px" alt="" srcset="images/inliner1_1-p-500.jpg 500w, images/inliner1_1.jpg 800w"></div>
    <div class="w-layout-hflex"><img src="images/inliner0_2.jpg" loading="lazy" width="400" sizes="(max-width: 479px) 100vw, 400px" alt="" srcset="images/inliner0_2-p-500.jpg 500w, images/inliner0_2.jpg 800w"><img src="images/inliner1_2.jpg" loading="lazy" width="400" sizes="(max-width: 479px) 100vw, 400px" alt="" srcset="images/inliner1_2-p-500.jpg 500w, images/inliner1_2.jpg 800w"></div>
    <p>After selected the best inliner points, I recalculated the homography matrix to get a better result.</p>
  </div>
  <div class="w-layout-blockcontainer w-container">
    <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Suspendisse varius enim in eros elementum tristique. Duis cursus, mi quis viverra ornare, eros dolor interdum nulla, ut commodo diam libero vitae erat. Aenean faucibus nibh et justo cursus id rutrum lorem imperdiet. Nunc ut sem vitae risus tristique posuere.</p>
    <h2>Blend Comparison</h2>
    <p>Left side is the manual blend images and right side is the auto blend images</p>
    <div class="w-layout-hflex"><img src="images/building_blend.jpg" loading="lazy" width="Auto" height="400" alt="" srcset="images/building_blend-p-500.jpg 500w, images/building_blend-p-800.jpg 800w, images/building_blend-p-1080.jpg 1080w, images/building_blend.jpg 1328w" sizes="(max-width: 479px) 100vw, 406.1125183105469px" class="image-7"><img src="images/building_blend_1.jpg" loading="lazy" width="Auto" height="400" alt="" srcset="images/building_blend_1-p-500.jpg 500w, images/building_blend_1-p-800.jpg 800w, images/building_blend_1-p-1080.jpg 1080w, images/building_blend_1.jpg 1163w" sizes="(max-width: 479px) 100vw, 371.8625183105469px"></div>
    <div class="w-layout-hflex"><img src="images/house0_house1_blend.jpg" loading="lazy" width="Auto" height="400" alt="" srcset="images/house0_house1_blend-p-500.jpg 500w, images/house0_house1_blend.jpg 540w" sizes="(max-width: 479px) 100vw, 394.1499938964844px" class="image-11"><img src="images/house_blend.jpg" loading="lazy" sizes="(max-width: 479px) 100vw, 371.9375px" height="400" alt="" srcset="images/house_blend.jpg 500w, images/house_blend.jpg 517w"></div>
    <div class="w-layout-hflex"><img src="images/view_blend.jpg" loading="lazy" width="Auto" height="300" alt="" srcset="images/view_blend-p-500.jpg 500w, images/view_blend-p-800.jpg 800w, images/view_blend-p-1080.jpg 1080w, images/view_blend-p-1600.jpg 1600w, images/view_blend-p-2000.jpg 2000w, images/view_blend-p-2600.jpg 2600w, images/view_blend.jpg 3144w" sizes="(max-width: 767px) 100vw, 497.9875183105469px" class="image-15"><img src="images/wth_blend.jpg" loading="lazy" sizes="(max-width: 479px) 100vw, 423.70001220703125px" height="300" alt="" srcset="images/wth_blend.jpg 500w, images/wth_blend.jpg 800w, images/wth_blend.jpg 1080w, images/wth_blend.jpg 1600w, images/wth_blend.jpg 2000w, images/wth_blend.jpg 2127w"></div>
  </div>
  <script src="https://d3e54v103j8qbb.cloudfront.net/js/jquery-3.5.1.min.dc5e7f18c8.js?site=670eca02bcb89791cb965a72" type="text/javascript" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin="anonymous"></script>
  <script src="js/webflow.js" type="text/javascript"></script>
</body>
</html>